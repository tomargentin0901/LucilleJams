from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from gensim.models.word2vec import Word2Vec
from gensim.models import KeyedVectors
import gensim.downloader
from config.tokenizer_config import tokenizer_config
from utils.dataset_utils import tokenize_songs
from ast import literal_eval
from typing import List, Union, Iterable, Dict
import pandas as pd
from abc import ABC, abstractmethod
from sklearn.metrics.pairwise import cosine_similarity as cs
from utils.dataset_utils import normalize_embeddings
import os
import numpy as np
from pathlib import Path
import shutil
import math


class Embeddings(ABC):

    def __init__(self, path_to_df: str):

        self.path_to_df = path_to_df
        self.__df = None

    @property
    def df(self) -> pd.DataFrame:
        if self.__df is None:
            self.load_df()
        return self.__df

    def load_df(self):
        self.__df = pd.read_csv(self.path_to_df, converters={"songs": literal_eval})


class TitlesEmbeddings(Embeddings):

    def __init__(self, path_to_df: str):
        super().__init__(path_to_df)


class Word2VecTitlesEmbeddings(TitlesEmbeddings):

    def __init__(self, model_name: str = "glove-wiki-gigaword-300"):

        self.model_name = model_name
        self.__model = None

    @property
    def model(self) -> Word2Vec:
        if self.__model is None:
            self.__model = self.get_model()
        return self.__model

    def get_model(self) -> Word2Vec:
        model_path = Path(gensim.downloader.info(self.model_name)["file_name"])
        if not model_path.exists():
            if self.model_name not in gensim.downloader.info()["models"].keys():
                raise ValueError("Model not available in gensim downloader.")
            model = gensim.downloader.load(self.model_name)
            # Place the model in the desired directory
            shutil.move(model_path, os.getcwd())
        else:
            model = KeyedVectors.load_word2vec_format(model_path, binary=False)
        return model

    @staticmethod
    def get_titles_embeddings(
        titles: Union[str, List[List[str]]],
        model: Word2Vec,
        pool_method: str = "median",
    ) -> np.ndarray:
        """
        Get embeddings for a list of titles using a Word2Vec model.
        The embeddings are generated by pooling the word embeddings of the words in the title.

        Args:
            titles (Union[str, List[List[str]]]): The titles to get embeddings for.
                Can be a single string or a list of lists of strings.
            model (Word2Vec): The Word2Vec model used for generating embeddings.
            pool_method (str, optional): The pooling method to use for aggregating word embeddings.
                Defaults to "median". Can be either "mean" or "median".

        Returns:
            np.ndarray: An array of title embeddings.

        Raises:
            ValueError: If an invalid pooling method is provided.

        """
        if not isinstance(titles, list):
            titles = [titles]
        titles_embeddings = np.zeros((len(titles), model.vector_size))
        for i, title in enumerate(titles):
            word_embeddings = []
            if not isinstance(title, str) and math.isnan(title):
                title = ""
            words = title.split()
            for word in words:
                word = word.lower()
                if word in model.index_to_key:
                    word_embeddings.append(model[word])
            if not word_embeddings:
                word_embeddings = np.zeros((model.vector_size,))
            if pool_method == "mean":
                title_embedding = np.mean(word_embeddings, axis=0)
            elif pool_method == "median":
                title_embedding = np.median(word_embeddings, axis=0)
            else:
                raise ValueError(
                    "Invalid pooling method. Choose between 'mean' and 'median'."
                )
            titles_embeddings[i, :] = title_embedding
        return titles_embeddings


class SongsEmbeddings(Embeddings):
    """Each playlist is made of songs, and each songs is made of an artist, a title, and the album it belongs to."""

    def __init__(self, path_to_df: str):

        super().__init__(path_to_df)
        self.__options = tokenizer_config

    def __iter__(self) -> Iterable[List[str]]:
        return tokenize_songs(self.df, self.__options)

    @abstractmethod  # Use of custom embeddings for the songs
    def build_model(self):
        pass


class Word2VecSongsEmbeddings(SongsEmbeddings):

    def __init__(
        self,
        is_already_trained: bool = True,
        path_to_df: str = None,
    ):
        super().__init__(path_to_df)
        self.is_already_trained = is_already_trained
        self.__model = None
        if (not self.is_already_trained) and (self.path_to_df is None):
            raise ValueError(
                "Path to the dataframe should be provided if the model is not already trained."
            )

    @property
    def model(self) -> Word2Vec:
        if self.__model is None and not self.is_already_trained:
            self.build_model()
        elif self.__model is None and self.is_already_trained:
            self.__model = Word2Vec.load("word2vec/songs_embeddings.bin")
        return self.__model

    def build_model(self):
        self.__model = Word2Vec(sentences=self, **self.config)
        if not os.path.exists("word2vec"):
            os.makedirs("word2vec")
        self.__model.save("word2vec/songs_embeddings.bin")

    @staticmethod
    def get_songs_playlists_embeddings(
        tokenized_songs: Union[List[str], List[List[str]]],
        model: Word2Vec,
        pool_method: str = "median",
    ) -> np.ndarray:
        """Create the songs playlist embeddings by averaging the embeddings of the songs in the playlist."""
        if (
            not tokenized_songs
        ):  # Handle the case where the playlist is empty and only the playlist title is provided.
            return np.zeros((1, model.vector_size))
        if not isinstance(tokenized_songs[0], list):
            tokenized_songs = [tokenized_songs]
        embedded_songs_playlists = np.zeros((len(tokenized_songs), model.vector_size))
        for i, songs in enumerate(tokenized_songs):
            array = np.array(
                [
                    model.wv[song]
                    for song in songs
                    if song in model.wv.key_to_index.keys()
                ]
            )
            if (
                not array.any()
            ):  # Handle the case where none of the songs in the playlist are in the vocabulary
                array = np.zeros(
                    (model.vector_size,)
                )  # TODO: Find a better way to handle this.
            if pool_method == "mean":
                playlist_vector = np.mean(array, axis=0)
            elif pool_method == "median":
                playlist_vector = np.median(array, axis=0)
            else:
                raise ValueError(
                    "Invalid pooling method. Choose between 'mean' and 'median'."
                )
            embedded_songs_playlists[i, :] = playlist_vector

        return embedded_songs_playlists

    @staticmethod
    def get_most_similar_songs_playlists(
        playlist_to_infer: np.ndarray,
        embedded_songs_playlists: np.ndarray,
        topn: int = 30,
    ) -> List[int]:
        """Get the most similar playlists to the playlist to infer."""
        similarities = cs(playlist_to_infer, embedded_songs_playlists).flatten()
        most_similar_playlists = np.argsort(similarities)[::-1][:topn]
        return most_similar_playlists


def get_playlist_embeddings(
    title_embeddings_model: TitlesEmbeddings,
    songs_embeddings_model: SongsEmbeddings,
    df: pd.DataFrame,
    pool_method: str = "median",
    alpha: float = 0.7,
    save: bool = True,
    verbose: bool = True,
):
    tokenized_songs = [song for song in tokenize_songs(df, tokenizer_config)]
    if verbose:
        print("1. Generating songs embeddings...")
    embedded_songs_playlists = normalize_embeddings(
        songs_embeddings_model.get_songs_playlists_embeddings(
            tokenized_songs, songs_embeddings_model.model, pool_method
        )
    )
    embedded_songs_playlists *= 1 / math.sqrt(alpha**2 + 1)  # Apply weight
    if verbose:
        print("2. Generating titles embeddings...")
    embedded_titles_playlists = normalize_embeddings(
        title_embeddings_model.get_titles_embeddings(
            list(df["title"].values), title_embeddings_model.model
        )
    )
    embedded_titles_playlists *= alpha / (math.sqrt(alpha**2 + 1))
    if verbose:
        print("3. Concatenation step. Generating playlists embeddings...")

    playlist_embeddings = np.concatenate(
        (
            embedded_titles_playlists,
            embedded_songs_playlists,
        ),
        axis=1,
    )
    # TODO: Generate embeddings.npy using weighted title and playlist content. Seems to differ...
    if save:
        np.save("embeddings.npy", playlist_embeddings)
    return playlist_embeddings


def __main__(
    df: pd.DataFrame,
    is_already_trained: bool = True,
    path_to_df: Union[Path, str] = None,
    pool_method: str = "median",
) -> np.ndarray:

    songs_embeddings_model = Word2VecSongsEmbeddings(is_already_trained, path_to_df)
    title_embeddings_model = Word2VecTitlesEmbeddings()
    playlist_embeddings = get_playlist_embeddings(
        title_embeddings_model, songs_embeddings_model, df, pool_method
    )
    return playlist_embeddings
